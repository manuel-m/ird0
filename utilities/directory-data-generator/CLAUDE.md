# Directory Data Generator

This document provides detailed guidance for working with the Directory Data Generator utility.

## Overview

The directory-data-generator is a standalone Java CLI application for generating realistic fake policyholder data for testing and development purposes.

**Key Features:**
- Generates realistic fake data using the Datafaker library
- Uses the actual `DirectoryEntry` model from the directory service (no duplication)
- Outputs CSV format compatible with the directory service
- Supports configurable record count with sensible defaults
- Built-in help and CLI argument parsing

**Use Case:**
Quickly generate large datasets for testing API performance, database operations, and data imports without manually creating test data.

## Architecture

This is a **plain Java CLI application** (not Spring Boot), built with:

- **Picocli** - CLI argument parsing with built-in help
- **Datafaker** - Realistic fake data generation (names, emails, addresses, etc.)
- **Apache Commons CSV** - Robust CSV writing (handles special characters, quoting)
- **Directory Module** - Depends on `DirectoryEntry` model directly (no code duplication)

## Building the Data Generator

**Build the utility along with the entire project:**
```bash
./mvnw clean package
```

**Build only the data generator module:**
```bash
./mvnw -f utilities/directory-data-generator/pom.xml clean package
```

**Output:**
`utilities/directory-data-generator/target/directory-data-generator.jar` (~69MB fat JAR)

**JAR Size Explanation:**
The JAR is large (~69MB) because it includes:
- Datafaker library and its dependencies
- Apache Commons CSV
- Picocli
- **Spring Boot libraries** (transitive from directory module dependency)

Even though this is not a Spring Boot application, it depends on the directory module which includes Spring Boot, so those libraries are bundled in the fat JAR.

## Using the Data Generator

### Basic Usage

**Generate 100 records (default):**
```bash
java -jar utilities/directory-data-generator/target/directory-data-generator.jar
```

**Output:** `policyholders.csv` (in current directory)

### Generate Specific Number of Records

```bash
java -jar utilities/directory-data-generator/target/directory-data-generator.jar 500
```

**Output:** 500 records in `policyholders.csv`

### Custom Output File

```bash
java -jar utilities/directory-data-generator/target/directory-data-generator.jar 200 -o custom-data.csv
```

**Output:** 200 records in `custom-data.csv`

### Show Help

```bash
java -jar utilities/directory-data-generator/target/directory-data-generator.jar --help
```

## Generated Data Format

The utility generates CSV files with the following structure:

```csv
name,type,email,phone,address,additionalInfo
"John Doe",individual,john.doe@example.com,555-1234,"123 Main St, Springfield, IL",Account since 1985-03-15
"Smith Family",family,smith@example.com,555-5678,"456 Oak Ave, Portland, OR",Members: 4
"Acme Corporation",corporate,acme.corporation@example.com,555-9012,"789 Business Blvd, NY","Industry: Technology, Employees: 250"
```

### Field Details

| Field | Description | Example |
|-------|-------------|---------|
| `name` | Type-specific realistic names | Person: "John Doe", Family: "Smith Family", Company: "Acme Corporation" |
| `type` | Randomly selected entry type | `individual`, `family`, or `corporate` |
| `email` | Generated based on the name | `john.doe@example.com` |
| `phone` | Realistic phone numbers | `555-1234` |
| `address` | Full street addresses | `123 Main St, Springfield, IL` |
| `additionalInfo` | Type-specific metadata | See below |

### Type-Specific Metadata (additionalInfo)

- **Individual**: Account creation date
  - Example: `Account since 1985-03-15`
- **Family**: Number of family members
  - Example: `Members: 4`
- **Corporate**: Industry and employee count
  - Example: `Industry: Technology, Employees: 250`

### Important Notes

- The CSV **does not include the `id` field** as it's auto-generated by the database
- All fields are properly quoted and escaped for safe CSV parsing
- Special characters in names and addresses are handled correctly

## Importing Generated Data

The CSV can be imported using various methods:

### Option 1: Manual API Calls (for small datasets)

```bash
# Skip the header line and POST each record
tail -n +2 policyholders.csv | while IFS=, read -r name type email phone address additionalInfo; do
  curl -X POST http://localhost:8081/api/policyholders \
    -H "Content-Type: application/json" \
    -d "{\"name\":$name,\"type\":$type,\"email\":$email,\"phone\":$phone,\"address\":$address,\"additionalInfo\":$additionalInfo}"
done
```

**Note:** This approach works for small datasets but is slow for large ones.

### Option 2: Direct SQLite Import

```bash
sqlite3 microservices/directory/policyholders.sqlite <<EOF
.mode csv
.import policyholders.csv directory_entry
EOF
```

**Note:** This is fast but requires direct database access and the service must be stopped.

### Option 3: Create a Bulk Import Endpoint (Recommended for large datasets)

Consider adding a POST endpoint to the Directory Service that accepts CSV files for bulk import:

```java
@PostMapping("/import")
public ResponseEntity<String> importCsv(@RequestParam("file") MultipartFile file) {
    // Parse CSV and batch insert records
}
```

This would provide fast, API-driven bulk imports without direct database access.

## Technical Details

### Architecture

- **Plain Java CLI** - No Spring Boot application context
- **Maven Shade Plugin** - Creates executable fat JAR with all dependencies
- **Picocli** - Command-line argument parsing with automatic help generation
- **Datafaker** - Generates realistic fake data
- **Apache Commons CSV** - Handles CSV writing with proper escaping

### Dependencies

Defined in `pom.xml`:

```xml
<dependencies>
    <!-- Fake data generation -->
    <dependency>
        <groupId>net.datafaker</groupId>
        <artifactId>datafaker</artifactId>
        <version>2.1.0</version>
    </dependency>

    <!-- CSV writing -->
    <dependency>
        <groupId>org.apache.commons</groupId>
        <artifactId>commons-csv</artifactId>
        <version>1.10.0</version>
    </dependency>

    <!-- CLI parsing -->
    <dependency>
        <groupId>info.picocli</groupId>
        <artifactId>picocli</artifactId>
        <version>4.7.5</version>
    </dependency>

    <!-- Directory model (pulls in Spring Boot transitively) -->
    <dependency>
        <groupId>com.ird0</groupId>
        <artifactId>directory</artifactId>
        <version>1.0.0</version>
    </dependency>
</dependencies>
```

### Build Configuration

The Maven Shade Plugin is configured to:

1. **Create executable fat JAR** - Bundles all dependencies
2. **Set main class** - `com.ird0.utilities.datagen.DataGeneratorCLI`
3. **Include transitive dependencies** - From directory module (including Spring Boot)

```xml
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-shade-plugin</artifactId>
    <version>3.5.0</version>
    <executions>
        <execution>
            <phase>package</phase>
            <goals>
                <goal>shade</goal>
            </goals>
            <configuration>
                <transformers>
                    <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                        <mainClass>com.ird0.utilities.datagen.DataGeneratorCLI</mainClass>
                    </transformer>
                </transformers>
            </configuration>
        </execution>
    </executions>
</plugin>
```

### Why Depend on Directory Module?

The data generator uses the `DirectoryEntry` model directly from the directory module:

```java
import com.ird0.directory.model.DirectoryEntry;
```

**Benefits:**
- **No code duplication** - Single source of truth for the model
- **Type safety** - Compiler enforces compatibility
- **Automatic updates** - Changes to DirectoryEntry automatically propagate

**Tradeoff:**
- Large JAR size due to transitive Spring Boot dependencies
- Acceptable tradeoff for maintaining a single model definition

### Data Generation Logic

The `PolicyholderDataGenerator` class uses Datafaker to generate realistic data:

```java
Faker faker = new Faker();

// Generate based on type
if (type.equals("individual")) {
    name = faker.name().fullName();
    additionalInfo = "Account since " + faker.date().birthday();
} else if (type.equals("family")) {
    name = faker.name().lastName() + " Family";
    additionalInfo = "Members: " + faker.number().numberBetween(2, 8);
} else { // corporate
    name = faker.company().name();
    additionalInfo = "Industry: " + faker.company().industry()
                   + ", Employees: " + faker.number().numberBetween(10, 500);
}
```

## File Paths

Key source files in `src/main/java/com/ird0/utilities/datagen/`:

- `DataGeneratorCLI.java` - CLI entry point with Picocli annotations
- `PolicyholderDataGenerator.java` - Data generation logic using Datafaker

## Examples

### Generate Small Test Dataset

```bash
# Generate 10 records for quick testing
java -jar utilities/directory-data-generator/target/directory-data-generator.jar 10
```

### Generate Large Dataset for Performance Testing

```bash
# Generate 10,000 records
java -jar utilities/directory-data-generator/target/directory-data-generator.jar 10000

# Import directly to SQLite
sqlite3 microservices/directory/policyholders.sqlite <<EOF
.mode csv
.import policyholders.csv directory_entry
EOF
```

### Generate Multiple Datasets

```bash
# Generate separate datasets for each instance
java -jar utilities/directory-data-generator/target/directory-data-generator.jar 1000 -o policyholders.csv
java -jar utilities/directory-data-generator/target/directory-data-generator.jar 500 -o experts.csv
java -jar utilities/directory-data-generator/target/directory-data-generator.jar 250 -o providers.csv
```

## Troubleshooting

| Issue | Solution                                                 |
|-------|----------------------------------------------------------|
| JAR not found | Run `./mvnw clean package` from root or module directory |
| Out of memory | Increase JVM heap: `java -Xmx512m -jar ...`              |
| CSV encoding issues | Ensure UTF-8 encoding for special characters             |
| Import fails | Check CSV format matches expected schema                 |
